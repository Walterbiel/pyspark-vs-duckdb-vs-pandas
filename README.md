# ğŸš€ AnÃ¡lise com 100 MilhÃµes de Linhas â€” PySpark vs DuckDB vs Pandas

Este projeto demonstra como lidar com grandes volumes de dados utilizando trÃªs tecnologias distintas: **PySpark**, **DuckDB** e **Pandas**.

O objetivo Ã© destacar os pontos fortes de cada abordagem na leitura, transformaÃ§Ã£o e anÃ¡lise de dados volumosos, **comparando suas performances em um mesmo cenÃ¡rio**.

---

## ğŸ“¦ Estrutura dos Dados

Os dados foram gerados de forma sintÃ©tica com `pandas` e `numpy`, simulando uma base com atÃ© **100 milhÃµes de registros**, contendo as seguintes colunas:

| Coluna      | Tipo     | DescriÃ§Ã£o                                |
|-------------|----------|------------------------------------------|
| `id`        | int      | Identificador Ãºnico sequencial           |
| `categoria` | str      | Categoria aleatÃ³ria (`A`, `B`, `C`, `D`) |
| `valor`     | float    | Valor monetÃ¡rio aleatÃ³rio                |
| `data`      | datetime | Datas aleatÃ³rias entre 2023 e 2025       |
| `flag`      | bool     | Valor booleano aleatÃ³rio                 |

---

## ğŸ“Š Consultas Realizadas

1. **Filtro por intervalo de datas + mÃ©dia por categoria**
2. **Contagem com mÃºltiplas condiÃ§Ãµes**
3. **Agrupamento por ano e categoria**
4. **MÃ©dia mÃ³vel (Janela de tempo)**
5. **Top 10 por categoria**

> âš ï¸ Mais quatro etapas serÃ£o adicionadas em breve nesta seÃ§Ã£o.

---

## ğŸ“ˆ Resultados â€” 1 MilhÃ£o de Linhas

### ğŸ”¥ PySpark

| Etapa                           | Tempo (s) |
|--------------------------------|-----------|
| Leitura e preparaÃ§Ã£o           | 5.10      |
| Filtro + mÃ©dia                 | 1.86      |
| Contagem com condiÃ§Ãµes         | 0.74      |
| Agrupamento por ano + categoria| 1.01      |
| MÃ©dia mÃ³vel                    | 0.38      |
| Top 10 por categoria           | 1.24      |
| **Tempo total**                | **10.33** |

### ğŸ¼ Pandas

| Etapa                           | Tempo (s) |
|--------------------------------|-----------|
| Leitura e preparaÃ§Ã£o           | 0.40      |
| Filtro + mÃ©dia                 | 0.06      |
| Contagem com condiÃ§Ãµes         | 0.07      |
| Agrupamento por ano + categoria| 0.12      |
| MÃ©dia mÃ³vel                    | 0.44      |
| Top 10 por categoria           | 0.39      |
| **Tempo total**                | **1.48**  |

### ğŸ¦† DuckDB

| Etapa                           | Tempo (s) |
|--------------------------------|-----------|
| Filtro + mÃ©dia                 | 0.18      |
| Contagem com condiÃ§Ãµes         | 0.12      |
| Agrupamento por ano + categoria| 0.13      |
| MÃ©dia mÃ³vel                    | 0.53      |
| Top 10 por categoria           | 0.37      |
| **Tempo total**                | **1.33**  |

---

## ğŸ“ˆ Resultados â€” 10 MilhÃµes de Linhas

| Tecnologia | Tempo Total (s) |
|------------|-----------------|
| PySpark    | 17.23           |
| Pandas     | 15.05           |
| DuckDB     | 10.83           |

---

## ğŸ“ˆ Resultados â€” 50 MilhÃµes de Linhas

| Tecnologia | Tempo Total (s) |
|------------|-----------------|
| PySpark    | 112.16          |
| Pandas     | 83.64           |
| DuckDB     | 60.23           |

---

## ğŸ“ˆ Resultados â€” 100 MilhÃµes de Linhas

| Tecnologia | Tempo Total (s) |
|------------|-----------------|
| PySpark    | 232.17          |
| Pandas     | 188.76          |
| DuckDB     | 161.37          |

---

## âš–ï¸ Comparativo entre Tecnologias

| Tecnologia | Pontos Fortes                                       | Quando Usar                                                  |
|------------|------------------------------------------------------|---------------------------------------------------------------|
| **PySpark**| Altamente escalÃ¡vel, ideal para clusters e Big Data  | Quando os dados excedem a capacidade de memÃ³ria               |
| **DuckDB** | Extremamente rÃ¡pido, executa localmente com SQL puro | Quando Ã© preciso performance local em datasets grandes        |
| **Pandas** | FlexÃ­vel e excelente para ajustes e visualizaÃ§Ãµes    | Ideal para anÃ¡lises pontuais, protÃ³tipos e dados menores      |

---

## ğŸ“Œ ConsideraÃ§Ãµes Finais

Este projeto demonstra que Ã© possÃ­vel lidar com dezenas â€” ou atÃ© centenas â€” de milhÃµes de registros **mesmo em ambiente local**, desde que a tecnologia certa seja escolhida para o cenÃ¡rio adequado.

Cada ferramenta tem seus pontos fortes. **CombinÃ¡-las estrategicamente** permite tirar o melhor proveito de cada uma: **escalabilidade, velocidade e flexibilidade**.

---

> Projeto desenvolvido por **Walter Gonzaga â€” WGG Digital Solutions**  
> ğŸ“¬ [LinkedIn](https://linkedin.com/in/walter-gonzaga) | ğŸŒ [wggsolutions.com](https://wggsolutions.com)
